#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ¸å¿ƒå¤„ç†é€»è¾‘ - ç»Ÿä¸€å¤„ç† REST å’Œ WebSocket è¯·æ±‚
"""
import asyncio
import logging
from typing import Dict, Any, List, Optional, Callable, Awaitable

from config import settings
from prompts import load_prompt
from core.llm import llm_manager, format_messages
from core.intent import recognize_intent, needs_expert, is_device_control, is_casual_chat
from core.query_rewriter import rewrite_query
from services.expert_consultation_service import expert_service
from services.device_expert_service import device_expert_service
from services.chat_history_service import save_message, get_history, format_history_for_llm
from services.web_search_service import web_search_service
from services.weather_service import weather_service

logger = logging.getLogger(__name__)


class ChatHandler:
    """
    èŠå¤©å¤„ç†å™¨ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
    
    å¤„ç†æµç¨‹:
    1. æ„å›¾è¯†åˆ«
    2. æ ¹æ®æ„å›¾è·¯ç”±åˆ°ä¸åŒå¤„ç†åˆ†æ”¯
    3. æ‰€æœ‰ç»“æœæœ€ç»ˆé€šè¿‡ thinking agent æ•´åˆè¾“å‡º
    """
    
    def __init__(self):
        pass
    
    async def process(
        self,
        query: str,
        session_id: str,
        context: Optional[Dict[str, Any]] = None,
        stream_callback: Optional[Callable[[str], Awaitable[None]]] = None,
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·è¯·æ±‚
        
        Args:
            query: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ ID
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            stream_callback: æµå¼å›è°ƒå‡½æ•°ï¼ˆç”¨äº WebSocketï¼‰
            
        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        logger.info(f"ğŸš€ æ”¶åˆ°è¯·æ±‚ | session={session_id} | query={query[:30]}...")
        context = context or {}
        
        # 1. è·å–å†å²å¯¹è¯è®°å½•
        history_records = get_history(session_id, limit=20)
        history = format_history_for_llm(history_records)
        
        # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        save_message(session_id=session_id, role="user", message=query)
        
        # 3. ğŸ”¥ å¯åŠ¨è”ç½‘æœç´¢ä»»åŠ¡ï¼ˆå¹¶è¡Œï¼Œä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        search_task = asyncio.create_task(web_search_service.search(query))
        logger.info(f"ğŸ” è”ç½‘æœç´¢ä»»åŠ¡å·²å¯åŠ¨")
        
        # 4. æ„å›¾è¯†åˆ«
        intent, intent_stats = await recognize_intent(query, history)
        logger.info(f"ğŸ¯ æ„å›¾: {intent}")
        
        # 5. ğŸŒ¤ï¸ å¤©æ°”æŸ¥è¯¢ï¼ˆåˆ¤æ–­æ˜¯å¦éœ€è¦æŸ¥å¤©æ°”ï¼Œéœ€è¦åˆ™æŸ¥è¯¢ï¼‰
        weather_info = await weather_service.check_and_query_weather(query)
        if weather_info:
            context["weather_info"] = weather_info
            context["weather_queried"] = True
            logger.info(f"ğŸŒ¤ï¸ å·²å°†å¤©æ°”ä¿¡æ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡: {weather_info.get('description', '')}")
        else:
            logger.info(f"ğŸŒ¤ï¸ æ— éœ€æŸ¥è¯¢å¤©æ°”æˆ–æŸ¥è¯¢å¤±è´¥")
        
        # 6. æ ¹æ®æ„å›¾å¤„ç†ï¼ˆä¼ å…¥ search_taskï¼Œåœ¨ thinking é˜¶æ®µåˆå¹¶ï¼‰
        response_content = ""
        metadata = {"intent": intent}
        
        try:
            if is_device_control(intent):
                # è®¾å¤‡æ§åˆ¶åˆ†æ”¯
                logger.info(f"â†’ è®¾å¤‡æ§åˆ¶")
                response_content, metadata = await self._handle_device_control(
                    query=query,
                    session_id=session_id,
                    context=context,
                    history=history,
                    stream_callback=stream_callback,
                    search_task=search_task,
                )
            elif needs_expert(intent):
                # æ•°æ®æŸ¥è¯¢/åˆ†æåˆ†æ”¯ - éœ€è¦ä¸“å®¶
                logger.info(f"â†’ æ•°æ®ä¸“å®¶")
                response_content, metadata = await self._handle_expert_query(
                    query=query,
                    session_id=session_id,
                    context=context,
                    history=history,
                    intent=intent,
                    stream_callback=stream_callback,
                    search_task=search_task,
                )
            else:
                # é—²èŠåˆ†æ”¯
                logger.info(f"â†’ é—²èŠ")
                response_content, metadata = await self._handle_casual_chat(
                    query=query,
                    context=context,
                    history=history,
                    stream_callback=stream_callback,
                    search_task=search_task,
                )
            
            metadata["intent"] = intent
            
        except Exception as e:
            logger.error(f"å¤„ç†è¯·æ±‚å¤±è´¥: {e}", exc_info=True)
            response_content = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
            metadata["error"] = str(e)
        
        # 5. ä¿å­˜ AI å›ç­”
        save_message(
            session_id=session_id,
            role="assistant",
            message=response_content,
            intent=intent,
            metadata=metadata,
        )
        
        logger.info(f"âœ… å®Œæˆ | intent={intent}")
        
        return {
            "status": "success" if "error" not in metadata else "error",
            "response": response_content,
            "intent": intent,
            "session_id": session_id,
            "metadata": metadata,
        }
    
    async def _handle_device_control(
        self,
        query: str,
        session_id: str,
        context: Dict[str, Any],
        history: List[Dict[str, str]],
        stream_callback: Optional[Callable[[str], Awaitable[None]]] = None,
        search_task: Optional[asyncio.Task] = None,
    ) -> tuple[str, Dict[str, Any]]:
        """å¤„ç†è®¾å¤‡æ§åˆ¶è¯·æ±‚"""
        
        if not settings.ENABLE_DEVICE_EXPERT:
            return "è®¾å¤‡æ§åˆ¶åŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·è”ç³»ç®¡ç†å‘˜", {"device_expert_enabled": False}
        
        try:
            # è°ƒç”¨è®¾å¤‡ä¸“å®¶æœåŠ¡
            device_response = await device_expert_service.consult(
                query=query,
                session_id=session_id,
                context=context,
                stream_callback=stream_callback,
            )
            
            if device_response.get("success"):
                # æå–è®¾å¤‡ä¸“å®¶çš„å›ç­”
                result = device_response.get("result", {})
                messages = result.get("messages", [])
                if messages:
                    device_answer = messages[0].get("content", "è®¾å¤‡æ“ä½œå®Œæˆ")
                else:
                    device_answer = "è®¾å¤‡æ“ä½œå®Œæˆ"
                
                # ğŸ”¥ ç­‰å¾…è”ç½‘æœç´¢ç»“æœ
                search_result = {}
                if search_task:
                    try:
                        search_result = await search_task
                        logger.info(f"ğŸ” è”ç½‘æœç´¢å®Œæˆï¼Œç»“æœæ•°: {len(search_result.get('results', []))}")
                    except Exception as e:
                        logger.warning(f"è”ç½‘æœç´¢å¤±è´¥: {e}")
                
                logger.info(f"â†’ thinkingæ•´åˆ")
                # é€šè¿‡ thinking agent æ•´åˆè¾“å‡º
                final_response = await self._thinking_integrate(
                    user_query=query,
                    raw_answer=device_answer,
                    source="è®¾å¤‡ä¸“å®¶",
                    context=context,
                    history=history,
                    stream_callback=stream_callback,
                    search_result=search_result,
                )
                
                return final_response, {
                    "device_expert_used": True,
                    "device_type": device_response.get("device_type"),
                    "success": True,
                    "web_search_used": search_result.get("success", False),
                }
            else:
                error = device_response.get("error", "æœªçŸ¥é”™è¯¯")
                logger.error(f"âŒ è®¾å¤‡ä¸“å®¶å¤±è´¥: {error}")
                return f"æŠ±æ­‰ï¼Œè®¾å¤‡æ“ä½œå¤±è´¥ï¼š{error}", {
                    "device_expert_used": True,
                    "success": False,
                    "error": error,
                }
                
        except Exception as e:
            logger.error(f"è®¾å¤‡æ§åˆ¶å¤±è´¥: {e}", exc_info=True)
            return f"æŠ±æ­‰ï¼Œè®¾å¤‡æ§åˆ¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}", {"error": str(e)}
    
    async def _handle_expert_query(
        self,
        query: str,
        session_id: str,
        context: Dict[str, Any],
        history: List[Dict[str, str]],
        intent: str,
        stream_callback: Optional[Callable[[str], Awaitable[None]]] = None,
        search_task: Optional[asyncio.Task] = None,
    ) -> tuple[str, Dict[str, Any]]:
        """å¤„ç†éœ€è¦ä¸“å®¶çš„æ•°æ®æŸ¥è¯¢/åˆ†æè¯·æ±‚"""
        
        # æŸ¥è¯¢é‡å†™
        rewritten_query, rewrite_stats = await rewrite_query(
            query=query,
            history=history,
            context=context,
        )
        
        if not settings.ENABLE_EXPERT_CONSULTATION:
            # ä¸“å®¶æœªå¯ç”¨ï¼Œä½¿ç”¨å…œåº•
            logger.warning(f"âš ï¸ æ•°æ®ä¸“å®¶æœªå¯ç”¨")
            return await self._handle_casual_chat(
                query=rewritten_query,
                context=context,
                history=history,
                stream_callback=stream_callback,
                search_task=search_task,
            )
        
        try:
            # è°ƒç”¨ä¸“å®¶æœåŠ¡
            expert_config = {
                "rag": {
                    "collection_name": "japan_shrimp",
                    "topk_single": 5,
                    "topk_multi": 5
                },
                "mode": "single",
                "single": {
                    "temperature": 0.4,
                    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæ—¥æœ¬é™†ä¸Šå…»æ®–é¢†åŸŸçš„ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç»“åˆå¢å¼ºæ£€ç´¢åçš„ç›¸å…³çŸ¥è¯†ï¼Œè¿›è¡Œæ•°æ®æŸ¥è¯¢ã€èšåˆåˆ†æï¼Œå¹¶ç»™å‡ºä¸“ä¸šçš„ç»“è®ºå’Œå»ºè®®ã€‚",
                    "max_tokens": 4096
                }
            }
            
            expert_response = await expert_service.consult(
                query=rewritten_query,
                context={
                    "original_query": query,
                    "intent": intent,
                    **context,
                },
                session_id=session_id,
                config=expert_config,
            )
            
            if expert_response.get("success"):
                expert_answer = expert_response.get("answer", "")
                
                # ğŸ”¥ ç­‰å¾…è”ç½‘æœç´¢ç»“æœ
                search_result = {}
                if search_task:
                    try:
                        search_result = await search_task
                        logger.info(f"ğŸ” è”ç½‘æœç´¢å®Œæˆï¼Œç»“æœæ•°: {len(search_result.get('results', []))}")
                    except Exception as e:
                        logger.warning(f"è”ç½‘æœç´¢å¤±è´¥: {e}")
                
                logger.info(f"â†’ thinkingæ•´åˆ")
                # é€šè¿‡ thinking agent æ•´åˆè¾“å‡º
                final_response = await self._thinking_integrate(
                    user_query=query,
                    raw_answer=expert_answer,
                    source="å…»æ®–ä¸“å®¶",
                    context=context,
                    history=history,
                    stream_callback=stream_callback,
                    search_result=search_result,
                )
                
                return final_response, {
                    "expert_consulted": True,
                    "confidence": expert_response.get("confidence", 0.0),
                    "web_search_used": search_result.get("success", False),
                }
            else:
                # ä¸“å®¶å’¨è¯¢å¤±è´¥ï¼Œä½¿ç”¨å…œåº•
                logger.warning(f"âš ï¸ æ•°æ®ä¸“å®¶å¤±è´¥: {expert_response.get('error')}")
                return await self._handle_casual_chat(
                    query=rewritten_query,
                    context=context,
                    history=history,
                    stream_callback=stream_callback,
                    search_task=search_task,
                )
                
        except Exception as e:
            logger.error(f"ä¸“å®¶å’¨è¯¢å¤±è´¥: {e}", exc_info=True)
            return await self._handle_casual_chat(
                query=rewritten_query,
                context=context,
                history=history,
                stream_callback=stream_callback,
                search_task=search_task,
            )
    
    async def _handle_casual_chat(
        self,
        query: str,
        context: Dict[str, Any],
        history: List[Dict[str, str]],
        stream_callback: Optional[Callable[[str], Awaitable[None]]] = None,
        search_task: Optional[asyncio.Task] = None,
    ) -> tuple[str, Dict[str, Any]]:
        """å¤„ç†é—²èŠè¯·æ±‚"""
        
        # åŠ è½½é—²èŠæç¤ºè¯
        system_prompt = load_prompt("chat")
        
        # æ„å»ºæ¶ˆæ¯
        messages = format_messages(
            system_prompt=system_prompt,
            user_message=query,
            history=history,
        )
        
        # è°ƒç”¨ LLM è·å–åˆæ­¥å›ç­”
        raw_answer = await llm_manager.invoke(
            messages=messages,
            stream=False,  # å…ˆä¸æµå¼ï¼Œç­‰ thinking æ•´åˆæ—¶å†æµå¼
        )
        
        # ğŸ”¥ ç­‰å¾…è”ç½‘æœç´¢ç»“æœ
        search_result = {}
        if search_task:
            try:
                search_result = await search_task
                logger.info(f"ğŸ” è”ç½‘æœç´¢å®Œæˆï¼Œç»“æœæ•°: {len(search_result.get('results', []))}")
            except Exception as e:
                logger.warning(f"è”ç½‘æœç´¢å¤±è´¥: {e}")
        
        # ğŸ”¥ é€šè¿‡ thinking agent æ•´åˆè¾“å‡ºï¼ˆç»Ÿä¸€åœ¨è¿™é‡Œä½¿ç”¨æœç´¢ç»“æœï¼‰
        logger.info(f"â†’ thinkingæ•´åˆ")
        final_response = await self._thinking_integrate(
            user_query=query,
            raw_answer=raw_answer,
            source="èŠå¤©åŠ©æ‰‹",
            context=context,
            history=history,
            stream_callback=stream_callback,
            search_result=search_result,
        )
        
        return final_response, {
            "chat_agent_used": True,
            "web_search_used": search_result.get("success", False),
        }
    
    async def _thinking_integrate(
        self,
        user_query: str,
        raw_answer: str,
        source: str,
        context: Dict[str, Any],
        history: List[Dict[str, str]],
        stream_callback: Optional[Callable[[str], Awaitable[None]]] = None,
        search_result: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        é€šè¿‡ thinking agent æ•´åˆè¾“å‡º
        
        æ‰€æœ‰å¤–éƒ¨æœåŠ¡ï¼ˆä¸“å®¶ã€è®¾å¤‡ï¼‰çš„å›ç­”éƒ½é€šè¿‡è¿™é‡Œæ•´åˆï¼Œ
        ç¡®ä¿è¾“å‡ºæ ¼å¼ä¸€è‡´ã€ä¸“ä¸šã€‚
        
        Args:
            user_query: ç”¨æˆ·åŸå§‹é—®é¢˜
            raw_answer: åŸå§‹å›ç­”ï¼ˆæ¥è‡ªä¸“å®¶æˆ–è®¾å¤‡æœåŠ¡ï¼‰
            source: å›ç­”æ¥æºï¼ˆå¦‚"å…»æ®–ä¸“å®¶"ã€"è®¾å¤‡ä¸“å®¶"ï¼‰
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            history: å¯¹è¯å†å²
            stream_callback: æµå¼å›è°ƒ
            search_result: è”ç½‘æœç´¢ç»“æœï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: æ•´åˆåçš„å›ç­”
        """
        # åŠ è½½ thinking æç¤ºè¯
        system_prompt = load_prompt("thinking")
        
        # æ„å»ºæ•´åˆæç¤º
        user_prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{user_query}

{source}å›ç­”ï¼š
{raw_answer}"""
        
        # ğŸŒ¤ï¸ å¦‚æœæœ‰å¤©æ°”ä¿¡æ¯ï¼Œè¿½åŠ åˆ°æç¤ºä¸­
        if context.get("weather_info"):
            weather_text = weather_service.format_for_context(context["weather_info"])
            if weather_text:
                user_prompt += f"""

{weather_text}"""
        
        # ğŸ”¥ å¦‚æœæœ‰è”ç½‘æœç´¢ç»“æœï¼Œè¿½åŠ åˆ°æç¤ºä¸­
        if search_result:
            search_text = web_search_service.format_for_llm(search_result)
            if search_text:
                user_prompt += f"""

{search_text}"""
        
        user_prompt += """

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæ•´åˆå¹¶ä¼˜åŒ–å›ç­”ï¼Œç¡®ä¿ï¼š
1. å›ç­”ä¸“ä¸šã€å‡†ç¡®
2. æ ¼å¼æ¸…æ™°ã€æ˜“è¯»
3. å¦‚æœ‰å¤©æ°”ä¿¡æ¯ï¼Œç»“åˆå¤©æ°”ç»™å‡ºå»ºè®®
4. å¦‚æœ‰è”ç½‘æœç´¢ç»“æœï¼Œå¯å‚è€ƒè¡¥å……æœ€æ–°ä¿¡æ¯
5. å¦‚æœ‰å¿…è¦ï¼Œè¡¥å……å¼•å¯¼é—®é¢˜"""
        
        # æ„å»ºæ¶ˆæ¯
        messages = format_messages(
            system_prompt=system_prompt,
            user_message=user_prompt,
            history=history,
        )
        
        # è°ƒç”¨ LLM
        response = await llm_manager.invoke(
            messages=messages,
            stream=stream_callback is not None,
            stream_callback=stream_callback,
        )
        
        return response


# å…¨å±€å¤„ç†å™¨å®ä¾‹
chat_handler = ChatHandler()

