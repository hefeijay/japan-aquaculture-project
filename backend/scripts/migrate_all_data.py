#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆæ•°æ®è¿ç§»è„šæœ¬ - ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰æ•°æ®è¿ç§»
æŒ‰ç…§ä¾èµ–å…³ç³»æ­£ç¡®é¡ºåºæ‰§è¡Œè¿ç§»ï¼Œç¡®ä¿å¤–é”®å…³ç³»å’ŒIDæ˜ å°„æ­£ç¡®
"""

import sys
import os
import csv
import json
from datetime import datetime
from decimal import Decimal
from collections import defaultdict

# æ·»åŠ  backend ç›®å½•åˆ°è·¯å¾„
backend_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, backend_dir)

from db_models.db_session import db_session_factory
import db_models  # å¯¼å…¥æ‰€æœ‰æ¨¡å‹
from db_models.pond import Pond
from db_models.batch import Batch
from db_models.device import Device, DeviceType
from db_models.sensor_type import SensorType
from db_models.camera import CameraImage, CameraHealth
from db_models.feeder_log import FeederLog
from db_models.sensor_reading import SensorReading
from db_models.shrimp_stats import ShrimpStats
from sqlalchemy import text


class DataMigrator:
    """æ•°æ®è¿ç§»å™¨ - ç®¡ç†æ‰€æœ‰è¿ç§»æµç¨‹å’ŒIDæ˜ å°„"""
    
    def __init__(self, session):
        self.session = session
        self.backend_dir = backend_dir
        
        # IDæ˜ å°„å­—å…¸
        self.pond_id_map = {}  # æ—§id -> æ–°id
        self.batch_id_map = {}  # æ—§id -> æ–°batch_id(æ•´æ•°ï¼Œæ•°æ®åº“ä¸»é”®)
        self.device_id_map = {}  # device_id(UUID) -> devices.id
        # æ—§ä¼ æ„Ÿå™¨ID -> device_id(UUID) -> devices.id çš„æ˜ å°„é“¾
        self.old_sensor_id_to_device_id = {}  # æ—§sensor.id -> device_id(UUID)
        # æ—§å–‚é£Ÿæœºç¼–å· -> device_id(UUID) -> devices.id çš„æ˜ å°„é“¾
        self.old_feeder_num_to_device_id = {}  # æ—§feederç¼–å· -> device_id(UUID)
        # æ—§æ‘„åƒå¤´ID -> device_id(UUID) -> devices.id çš„æ˜ å°„é“¾
        self.old_camera_id_to_device_id = {}  # æ—§camera_id -> device_id(UUID)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = defaultdict(lambda: {'success': 0, 'skip': 0, 'error': 0})
    
    def print_section(self, title, step=None):
        """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
        print("\n" + "=" * 70)
        if step:
            print(f"æ­¥éª¤ {step}: {title}")
        else:
            print(title)
        print("=" * 70)
    
    def migrate_ponds(self):
        """æ­¥éª¤1: è¿ç§»æ± å­æ•°æ®"""
        self.print_section("è¿ç§»æ± å­æ•°æ® (ponds.csv)", 1)
        
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/ponds.csv')
        if not os.path.exists(csv_path):
            print("  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    old_id = int(row['id'])
                    
                    # ç”Ÿæˆä¸šåŠ¡ID: POND_001, POND_002, ...
                    pond_id = f"POND_{old_id:03d}"
                    
                    # ä½¿ç”¨åŸç”ŸSQLæ’å…¥ï¼Œä¿ç•™åŸID
                    self.session.execute(text("""
                        INSERT INTO ponds (id, pond_id, name, location, area, count, description)
                        VALUES (:id, :pond_id, :name, :location, :area, :count, :description)
                        ON DUPLICATE KEY UPDATE name=VALUES(name)
                    """), {
                        'id': old_id,
                        'pond_id': pond_id,
                        'name': row['name'],
                        'location': row.get('location'),
                        'area': Decimal(row['area']) if row.get('area') else None,
                        'count': int(row['count']) if row.get('count') else 0,
                        'description': row.get('description')
                    })
                    
                    self.pond_id_map[old_id] = old_id
                    self.stats['ponds']['success'] += 1
                    
                except Exception as e:
                    self.stats['ponds']['error'] += 1
                    print(f"  âŒ é”™è¯¯ (id={row.get('id')}): {e}")
        
        self.session.commit()
        print(f"  âœ“ å®Œæˆ: {self.stats['ponds']['success']} æˆåŠŸ, {self.stats['ponds']['error']} å¤±è´¥")
    
    def migrate_batches(self):
        """æ­¥éª¤2: è¿ç§»æ‰¹æ¬¡æ•°æ®"""
        self.print_section("è¿ç§»æ‰¹æ¬¡æ•°æ® (batches.csv)", 2)
        
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/batches.csv')
        if not os.path.exists(csv_path):
            print("  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    old_batch_id = int(row['batch_id'])
                    old_pool_id = int(row['pool_id'])
                    
                    # æ˜ å°„ pond_id (pool_id=4 -> pond_id=1)
                    new_pond_id = 1 if old_pool_id == 4 else self.pond_id_map.get(old_pool_id, 1)
                    
                    # æ˜ å°„æ•°æ®åº“ID (æ—§çš„2 -> æ–°çš„1)
                    new_db_id = 1 if old_batch_id == 2 else old_batch_id
                    
                    # ç”Ÿæˆä¸šåŠ¡ID: BATCH_2024_001, BATCH_2024_002, ...
                    # ä» start_date æå–å¹´ä»½ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ 2024
                    year = '2024'
                    if row.get('start_date'):
                        try:
                            year = row['start_date'][:4]
                        except:
                            pass
                    business_batch_id = f"BATCH_{year}_{new_db_id:03d}"
                    
                    self.session.execute(text("""
                        INSERT INTO batches (
                            id, batch_id, pond_id, start_date, species, location,
                            seed_origin, stocking_density, end_date, notes
                        ) VALUES (
                            :id, :batch_id, :pond_id, :start_date, :species, :location,
                            :seed_origin, :stocking_density, :end_date, :notes
                        )
                        ON DUPLICATE KEY UPDATE species=VALUES(species)
                    """), {
                        'id': new_db_id,
                        'batch_id': business_batch_id,
                        'pond_id': new_pond_id,
                        'start_date': row.get('start_date'),
                        'species': row.get('species'),
                        'location': row.get('location'),
                        'seed_origin': row.get('seed_origin'),
                        'stocking_density': Decimal(row['stocking_density']) if row.get('stocking_density') else None,
                        'end_date': row.get('end_date'),
                        'notes': row.get('notes')
                    })
                    
                    self.batch_id_map[old_batch_id] = new_db_id  # å­˜å‚¨æ•°æ®åº“ä¸»é”®IDï¼ˆæ•´æ•°ï¼‰
                    self.stats['batches']['success'] += 1
                    
                except Exception as e:
                    self.stats['batches']['error'] += 1
                    print(f"  âŒ é”™è¯¯ (batch_id={row.get('batch_id')}): {e}")
        
        self.session.commit()
        print(f"  âœ“ å®Œæˆ: {self.stats['batches']['success']} æˆåŠŸ, {self.stats['batches']['error']} å¤±è´¥")
    
    def migrate_device_types(self):
        """æ­¥éª¤3: è¿ç§»è®¾å¤‡ç±»å‹"""
        self.print_section("åˆå§‹åŒ–è®¾å¤‡ç±»å‹ (device_types)", 3)
        
        device_types = [
            (2, 'camera', 'æ‘„åƒå¤´', 'ç›‘æ§æ‘„åƒå¤´'),
            (3, 'sensor', 'ä¼ æ„Ÿå™¨', 'å„ç±»ä¼ æ„Ÿå™¨è®¾å¤‡'),
            (4, 'feeder', 'å–‚é£Ÿæœº', 'è‡ªåŠ¨å–‚é£Ÿè®¾å¤‡'),
            (5, 'water_pump', 'å¾ªç¯æ°´æ³µ', 'å¾ªç¯æ°´æ³µè®¾å¤‡'),
            (6, 'air_blower', 'é¼“é£æœº', 'é¼“é£æœºè®¾å¤‡'),
            (7, 'water_switch', 'æ°´é¾™å¤´å¼€å…³', 'æ°´é¾™å¤´å¼€å…³è®¾å¤‡'),
            (8, 'solar_heater_pump', 'å¤ªé˜³èƒ½åŠ çƒ­å™¨å¾ªç¯æ³µ', 'å¤ªé˜³èƒ½åŠ çƒ­å™¨å¾ªç¯æ³µè®¾å¤‡'),
        ]
        
        for type_id, category, name, description in device_types:
            try:
                self.session.execute(text("""
                    INSERT INTO device_types (id, category, name, description)
                    VALUES (:id, :category, :name, :description)
                    ON DUPLICATE KEY UPDATE name=VALUES(name), description=VALUES(description)
                """), {
                    'id': type_id,
                    'category': category,
                    'name': name,
                    'description': description
                })
                self.stats['device_types']['success'] += 1
            except Exception as e:
                self.stats['device_types']['error'] += 1
                print(f"  âŒ é”™è¯¯ (id={type_id}): {e}")
        
        self.session.commit()
        print(f"  âœ“ å®Œæˆ: {self.stats['device_types']['success']} æˆåŠŸ")
    
    def migrate_sensor_types(self):
        """æ­¥éª¤4: è¿ç§»ä¼ æ„Ÿå™¨ç±»å‹"""
        self.print_section("è¿ç§»ä¼ æ„Ÿå™¨ç±»å‹ (sensor_types.csv)", 4)
        
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/sensor_types.csv')
        if not os.path.exists(csv_path):
            print("  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    self.session.execute(text("""
                        INSERT INTO sensor_types (
                            id, type_name, metric, unit, valid_min, valid_max, description
                        ) VALUES (
                            :id, :type_name, :metric, :unit, :valid_min, :valid_max, :description
                        )
                        ON DUPLICATE KEY UPDATE type_name=VALUES(type_name)
                    """), {
                        'id': int(row['id']),
                        'type_name': row['type_name'],
                        'metric': row.get('metric'),
                        'unit': row.get('unit'),
                        'valid_min': Decimal(row['valid_min']) if row.get('valid_min') else None,
                        'valid_max': Decimal(row['valid_max']) if row.get('valid_max') else None,
                        'description': row.get('description')
                    })
                    self.stats['sensor_types']['success'] += 1
                except Exception as e:
                    self.stats['sensor_types']['error'] += 1
                    print(f"  âŒ é”™è¯¯ (id={row.get('id')}): {e}")
        
        self.session.commit()
        print(f"  âœ“ å®Œæˆ: {self.stats['sensor_types']['success']} æˆåŠŸ")
    
    def migrate_devices_and_extensions(self):
        """æ­¥éª¤5: è¿ç§»è®¾å¤‡åŠæ‰©å±•ï¼ˆä¼ æ„Ÿå™¨ã€å–‚é£Ÿæœºã€æ‘„åƒå¤´ï¼‰"""
        self.print_section("è¿ç§»è®¾å¤‡åŠæ‰©å±•æ•°æ®", 5)
        
        # 5.1 è¿ç§»ä¼ æ„Ÿå™¨è®¾å¤‡
        print("\n  5.1 è¿ç§»ä¼ æ„Ÿå™¨è®¾å¤‡...")
        self._migrate_sensors()
        
        # 5.2 è¿ç§»å–‚é£Ÿæœºè®¾å¤‡
        print("\n  5.2 è¿ç§»å–‚é£Ÿæœºè®¾å¤‡...")
        self._migrate_feeders()
        
        # 5.3 è¿ç§»æ‘„åƒå¤´è®¾å¤‡
        print("\n  5.3 è¿ç§»æ‘„åƒå¤´è®¾å¤‡...")
        self._migrate_cameras()
        
        self.session.commit()
        print(f"\n  âœ“ è®¾å¤‡è¿ç§»å®Œæˆ:")
        print(f"    - ä¼ æ„Ÿå™¨: {self.stats['sensors']['success']} æˆåŠŸ")
        print(f"    - å–‚é£Ÿæœº: {self.stats['feeders']['success']} æˆåŠŸ")
        print(f"    - æ‘„åƒå¤´: {self.stats['cameras']['success']} æˆåŠŸ")
    
    def _migrate_sensors(self):
        """è¿ç§»ä¼ æ„Ÿå™¨è®¾å¤‡ï¼ˆåªåˆ›å»ºDeviceè®°å½•ï¼Œä¸å†åˆ›å»ºSensoræ‰©å±•è¡¨ï¼‰"""
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/sensors.csv')
        if not os.path.exists(csv_path):
            return
        
        # çŠ¶æ€å€¼è½¬æ¢å‡½æ•°
        def normalize_status(status):
            if not status:
                return 'online'
            status_lower = str(status).lower()
            if status_lower in ['activate', 'active', 'åœ¨çº¿', 'æ­£å¸¸']:
                return 'online'
            elif status_lower in ['deactivate', 'inactive', 'ç¦»çº¿', 'å¼‚å¸¸']:
                return 'offline'
            return 'online'  # é»˜è®¤å€¼
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    old_sensor_id = int(row['id'])
                    sensor_uuid = row['sensor_id']
                    sensor_type_id = int(row['sensor_type_id']) if row.get('sensor_type_id') and row['sensor_type_id'].strip() else None
                    
                    # åˆ›å»º Deviceï¼ˆä¼ æ„Ÿå™¨ç±»å‹ï¼Œdevice_type_id=3ï¼‰
                    # å¦‚æœsensor_type_idä¸ºNoneï¼Œä½¿ç”¨NULL
                    if sensor_type_id is not None:
                        self.session.execute(text("""
                            INSERT INTO devices (
                                device_id, name, device_type_id, sensor_type_id, model, location, 
                                pond_id, status, ownership, control_mode, is_deleted
                            ) VALUES (
                                :device_id, :name, 3, :sensor_type_id, :model, :location, 
                                1, :status, 'own', 'hybrid', 0
                            )
                            ON DUPLICATE KEY UPDATE name=VALUES(name), sensor_type_id=VALUES(sensor_type_id)
                        """), {
                            'device_id': sensor_uuid,
                            'name': row.get('name', f'ä¼ æ„Ÿå™¨-{old_sensor_id}').strip(),
                            'sensor_type_id': sensor_type_id,
                            'model': row.get('model', 'sensor') or 'sensor',
                            'location': row.get('location'),
                            'status': normalize_status(row.get('status'))
                        })
                    else:
                        self.session.execute(text("""
                            INSERT INTO devices (
                                device_id, name, device_type_id, model, location, 
                                pond_id, status, ownership, control_mode, is_deleted
                            ) VALUES (
                                :device_id, :name, 3, :model, :location, 
                                1, :status, 'own', 'hybrid', 0
                            )
                            ON DUPLICATE KEY UPDATE name=VALUES(name)
                        """), {
                            'device_id': sensor_uuid,
                            'name': row.get('name', f'ä¼ æ„Ÿå™¨-{old_sensor_id}').strip(),
                            'model': row.get('model', 'sensor') or 'sensor',
                            'location': row.get('location'),
                            'status': normalize_status(row.get('status'))
                        })
                    self.session.flush()
                    
                    # è·å– device.id
                    device = self.session.query(Device).filter(Device.device_id == sensor_uuid).first()
                    if not device:
                        continue
                    
                    # ä¿å­˜æ˜ å°„ï¼šæ—§sensor.id -> device_id(UUID) -> devices.id
                    self.device_id_map[sensor_uuid] = device.id
                    self.old_sensor_id_to_device_id[old_sensor_id] = sensor_uuid
                    self.stats['sensors']['success'] += 1
                    
                except Exception as e:
                    self.stats['sensors']['error'] += 1
                    if self.stats['sensors']['error'] <= 5:
                        print(f"    âŒ ä¼ æ„Ÿå™¨é”™è¯¯ (id={row.get('id')}): {e}")
    
    def _migrate_feeders(self):
        """è¿ç§»å–‚é£Ÿæœºè®¾å¤‡ï¼ˆåªåˆ›å»ºDeviceè®°å½•ï¼Œä¸å†åˆ›å»ºFeederæ‰©å±•è¡¨ï¼‰"""
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/devices.csv')
        if not os.path.exists(csv_path):
            return
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    device_uuid = row['device_id']
                    device_name = row.get('name', '').lower()
                    
                    # å–‚é£Ÿæœºçš„æ ‡è¯†ï¼š
                    # 1. device_id ä»¥ 'feeder_' å¼€å¤´
                    # 2. name åŒ…å« 'feed' æˆ– 'robot'
                    is_feeder = (device_uuid and device_uuid.startswith('feeder_')) or \
                                ('feed' in device_name) or ('robot' in device_name)
                    
                    if not is_feeder:
                        continue
                    
                    # çŠ¶æ€å€¼è½¬æ¢å‡½æ•°
                    def normalize_status(status):
                        if not status:
                            return 'online'
                        status_lower = str(status).lower()
                        if status_lower in ['activate', 'active', 'åœ¨çº¿', 'æ­£å¸¸']:
                            return 'online'
                        elif status_lower in ['deactivate', 'inactive', 'ç¦»çº¿', 'å¼‚å¸¸']:
                            return 'offline'
                        return 'online'  # é»˜è®¤å€¼
                    
                    # åˆ›å»º Deviceï¼ˆå–‚é£Ÿæœºç±»å‹ï¼Œdevice_type_id=4ï¼‰
                    self.session.execute(text("""
                        INSERT INTO devices (
                            device_id, name, device_type_id, model, manufacturer,
                            location, pond_id, status, control_mode, ownership, is_deleted
                        ) VALUES (
                            :device_id, :name, 4, :model, :manufacturer,
                            :location, 1, :status, :control_mode, 'own', 0
                        )
                        ON DUPLICATE KEY UPDATE name=VALUES(name)
                    """), {
                        'device_id': device_uuid,
                        'name': row.get('name', 'Feeder'),
                        'model': row.get('model') or None,
                        'manufacturer': row.get('manufacturer') or None,
                        'location': row.get('location') or None,
                        'status': normalize_status(row.get('status')),
                        'control_mode': row.get('control_mode', 'hybrid')
                    })
                    self.session.flush()
                    
                    # è·å– device.id
                    device = self.session.query(Device).filter(Device.device_id == device_uuid).first()
                    if not device:
                        continue
                    
                    # ä¿å­˜æ˜ å°„
                    self.device_id_map[device_uuid] = device.id
                    
                    # æå–å–‚é£Ÿæœºç¼–å·å¹¶ä¿å­˜æ˜ å°„
                    feeder_num = None
                    if device_uuid.startswith('feeder_'):
                        try:
                            feeder_num = int(device_uuid.replace('feeder_', ''))
                            self.old_feeder_num_to_device_id[str(feeder_num)] = device_uuid
                        except:
                            pass
                    
                    self.stats['feeders']['success'] += 1
                    
                except Exception as e:
                    self.stats['feeders']['error'] += 1
                    if self.stats['feeders']['error'] <= 5:
                        print(f"    âŒ å–‚é£Ÿæœºé”™è¯¯: {e}")
    
    def _migrate_cameras(self):
        """è¿ç§»æ‘„åƒå¤´è®¾å¤‡ï¼ˆåªåˆ›å»ºDeviceè®°å½•ï¼Œä¸å†åˆ›å»ºCameraæ‰©å±•è¡¨ï¼‰"""
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/camera_status.csv')
        if not os.path.exists(csv_path):
            return
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    old_camera_id = int(row['camera_id'])
                    camera_uuid = f"camera_{old_camera_id}"
                    
                    # åˆ›å»º Deviceï¼ˆæ‘„åƒå¤´ç±»å‹ï¼Œdevice_type_id=2ï¼‰
                    # æ‘„åƒå¤´ä¸“å±é…ç½®å¯ä»¥å­˜å‚¨åœ¨ device_specific_config JSON å­—æ®µä¸­
                    device_config = {}
                    if row.get('connectivity'):
                        device_config['connectivity'] = int(row['connectivity'])
                    if row.get('fps'):
                        device_config['fps'] = int(row['fps'])
                    if row.get('recording'):
                        device_config['recording'] = row.get('recording', '').lower() == 'true'
                    if row.get('night_vision'):
                        device_config['night_vision'] = row.get('night_vision', '').lower() == 'true'
                    if row.get('motion_detection'):
                        device_config['motion_detection'] = row.get('motion_detection', '').lower() == 'true'
                    if row.get('quality'):
                        device_config['quality'] = row['quality']
                    if row.get('temperature'):
                        device_config['temperature'] = float(row['temperature'])
                    if row.get('resolution'):
                        device_config['resolution'] = row['resolution']
                    
                    config_json = json.dumps(device_config) if device_config else None
                    
                    # çŠ¶æ€å€¼è½¬æ¢å‡½æ•°
                    def normalize_status(status):
                        if not status:
                            return 'online'
                        status_lower = str(status).lower()
                        if status_lower in ['activate', 'active', 'åœ¨çº¿', 'æ­£å¸¸']:
                            return 'online'
                        elif status_lower in ['deactivate', 'inactive', 'ç¦»çº¿', 'å¼‚å¸¸']:
                            return 'offline'
                        return 'online'  # é»˜è®¤å€¼
                    
                    self.session.execute(text("""
                        INSERT INTO devices (
                            device_id, name, device_type_id, location, pond_id, 
                            status, ownership, control_mode, device_specific_config, is_deleted
                        ) VALUES (
                            :device_id, :name, 2, :location, 1, 
                            :status, 'own', 'hybrid', :device_specific_config, 0
                        )
                        ON DUPLICATE KEY UPDATE name=VALUES(name), device_specific_config=VALUES(device_specific_config)
                    """), {
                        'device_id': camera_uuid,
                        'name': row.get('name', f'æ‘„åƒå¤´-{old_camera_id}'),
                        'location': row.get('location'),
                        'status': normalize_status(row.get('status')),
                        'device_specific_config': config_json
                    })
                    self.session.flush()
                    
                    # è·å– device.id
                    device = self.session.query(Device).filter(Device.device_id == camera_uuid).first()
                    if not device:
                        continue
                    
                    # ä¿å­˜æ˜ å°„ï¼šæ—§camera_id -> device_id(UUID) -> devices.id
                    self.device_id_map[camera_uuid] = device.id
                    self.old_camera_id_to_device_id[old_camera_id] = camera_uuid
                    self.stats['cameras']['success'] += 1
                    
                except Exception as e:
                    self.stats['cameras']['error'] += 1
                    if self.stats['cameras']['error'] <= 5:
                        print(f"    âŒ æ‘„åƒå¤´é”™è¯¯ (camera_id={row.get('camera_id')}): {e}")
    
    def migrate_sensor_readings(self):
        """æ­¥éª¤6: è¿ç§»ä¼ æ„Ÿå™¨è¯»æ•°ï¼ˆä½¿ç”¨device_idè€Œä¸æ˜¯sensor_idï¼‰"""
        self.print_section("è¿ç§»ä¼ æ„Ÿå™¨è¯»æ•° (sensor_readings.csv)", 6)
        
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/sensor_readings.csv')
        if not os.path.exists(csv_path):
            print("  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return
        
        print(f"  ğŸ“Š ä¼ æ„Ÿå™¨è®¾å¤‡æ˜ å°„: {len(self.old_sensor_id_to_device_id)} ä¸ª")
        
        # å»ºç«‹ device_id -> metric çš„æ˜ å°„ï¼ˆä»Deviceå’ŒSensorTypeè·å–ï¼‰
        device_to_metric = {}
        devices = self.session.query(Device).filter(Device.device_type_id == 3).all()  # åªæŸ¥è¯¢ä¼ æ„Ÿå™¨è®¾å¤‡
        for device in devices:
            if device.sensor_type_id:
                sensor_type = self.session.query(SensorType).filter(SensorType.id == device.sensor_type_id).first()
                if sensor_type and sensor_type.metric:
                    device_to_metric[device.id] = sensor_type.metric
        
        print(f"  ğŸ“Š è®¾å¤‡metricæ˜ å°„: {len(device_to_metric)} ä¸ª")
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    old_sensor_id = int(row['sensor_id'])
                    # é€šè¿‡æ—§sensor_idæ‰¾åˆ°device_idï¼Œå†æ‰¾åˆ°devices.id
                    device_uuid = self.old_sensor_id_to_device_id.get(old_sensor_id)
                    if not device_uuid:
                        self.stats['sensor_readings']['error'] += 1
                        continue
                    
                    device_db_id = self.device_id_map.get(device_uuid)
                    if not device_db_id:
                        self.stats['sensor_readings']['error'] += 1
                        continue
                    
                    # è§£ææ—¶é—´
                    ts_utc = None
                    if row.get('ts_utc'):
                        try:
                            ts_utc = datetime.strptime(row['ts_utc'], '%Y-%m-%d %H:%M:%S.%f')
                        except:
                            try:
                                ts_utc = datetime.strptime(row['ts_utc'], '%Y-%m-%d %H:%M:%S')
                            except:
                                ts_utc = datetime.utcnow()
                    
                    if not ts_utc:
                        ts_utc = datetime.utcnow()
                    
                    value = float(row['value']) if row.get('value') else 0.0
                    
                    reading = SensorReading(
                        device_id=device_db_id,  # ä½¿ç”¨device_idè€Œä¸æ˜¯sensor_id
                        pond_id=1,
                        value=value
                    )
                    
                    if self.batch_id_map:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®åº“ä¸»é”®IDï¼ˆæ•´æ•°ï¼‰
                        reading.batch_id = list(self.batch_id_map.values())[0]
                    reading.ts_utc = ts_utc
                    
                    # å¡«å…… metricï¼ˆå¿«ç…§å­—æ®µï¼Œä» sensor_types åŒæ­¥ï¼‰
                    metric = device_to_metric.get(device_db_id)
                    if metric:
                        reading.metric = metric
                    
                    if row.get('unit'):
                        reading.unit = row['unit']
                    if row.get('quality_flag'):
                        reading.quality_flag = row['quality_flag']
                    
                    self.session.add(reading)
                    self.stats['sensor_readings']['success'] += 1
                    
                    if self.stats['sensor_readings']['success'] % 5000 == 0:
                        self.session.flush()
                        print(f"  è¿›åº¦: {self.stats['sensor_readings']['success']} æ¡...")
                    
                except Exception as e:
                    self.stats['sensor_readings']['error'] += 1
                    if self.stats['sensor_readings']['error'] <= 5:
                        print(f"  âŒ é”™è¯¯: {e}")
        
        self.session.commit()
        print(f"  âœ“ å®Œæˆ: {self.stats['sensor_readings']['success']} æˆåŠŸ, {self.stats['sensor_readings']['error']} å¤±è´¥")
    
    def migrate_feeder_logs(self):
        """æ­¥éª¤7: è¿ç§»å–‚é£Ÿæœºæ—¥å¿—ï¼ˆä½¿ç”¨device_idè€Œä¸æ˜¯feeder_idï¼‰"""
        self.print_section("è¿ç§»å–‚é£Ÿæœºæ—¥å¿— (feeders_logs.csv)", 7)
        
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/feeders_logs.csv')
        if not os.path.exists(csv_path):
            print("  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return
        
        print(f"  ğŸ“Š å–‚é£Ÿæœºè®¾å¤‡æ˜ å°„: {len(self.old_feeder_num_to_device_id)} ä¸ª")
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    feeder_id_str = str(row['feeder_id'])
                    # é€šè¿‡æ—§feederç¼–å·æ‰¾åˆ°device_idï¼Œå†æ‰¾åˆ°devices.id
                    device_uuid = self.old_feeder_num_to_device_id.get(feeder_id_str)
                    if not device_uuid:
                        self.stats['feeder_logs']['error'] += 1
                        continue
                    
                    device_db_id = self.device_id_map.get(device_uuid)
                    if not device_db_id:
                        self.stats['feeder_logs']['error'] += 1
                        continue
                    
                    # è§£ææ—¶é—´
                    ts_utc = None
                    if row.get('ts_utc'):
                        try:
                            ts_utc = datetime.strptime(row['ts_utc'], '%Y-%m-%d %H:%M:%S.%f')
                        except:
                            try:
                                ts_utc = datetime.strptime(row['ts_utc'], '%Y-%m-%d %H:%M:%S')
                            except:
                                ts_utc = datetime.utcnow()
                    
                    if not ts_utc:
                        ts_utc = datetime.utcnow()
                    
                    log = FeederLog(
                        device_id=device_db_id,  # ä½¿ç”¨device_idè€Œä¸æ˜¯feeder_id
                        pond_id=1,
                        ts_utc=ts_utc,
                        status=row.get('status', 'ok')
                    )
                    
                    if self.batch_id_map:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®åº“ä¸»é”®IDï¼ˆæ•´æ•°ï¼‰
                        log.batch_id = list(self.batch_id_map.values())[0]
                    if row.get('feed_amount_g'):
                        log.feed_amount_g = Decimal(row['feed_amount_g'])
                    if row.get('notes'):
                        log.notes = row['notes']
                    
                    self.session.add(log)
                    self.stats['feeder_logs']['success'] += 1
                    
                    if self.stats['feeder_logs']['success'] % 500 == 0:
                        self.session.flush()
                        print(f"  è¿›åº¦: {self.stats['feeder_logs']['success']} æ¡...")
                    
                except Exception as e:
                    self.stats['feeder_logs']['error'] += 1
                    if self.stats['feeder_logs']['error'] <= 5:
                        print(f"  âŒ é”™è¯¯: {e}")
        
        self.session.commit()
        print(f"  âœ“ å®Œæˆ: {self.stats['feeder_logs']['success']} æˆåŠŸ, {self.stats['feeder_logs']['error']} å¤±è´¥")
    
    def migrate_camera_images(self):
        """æ­¥éª¤8: è¿ç§»æ‘„åƒå¤´å›¾ç‰‡ï¼ˆä½¿ç”¨device_idè€Œä¸æ˜¯camera_idï¼‰"""
        self.print_section("è¿ç§»æ‘„åƒå¤´å›¾ç‰‡ (camera_images.csv)", 8)
        
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/camera_images.csv')
        if not os.path.exists(csv_path):
            print("  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return
        
        print(f"  ğŸ“Š æ‘„åƒå¤´è®¾å¤‡æ˜ å°„: {len(self.old_camera_id_to_device_id)} ä¸ª")
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    old_camera_id = int(row['camera_id'])
                    # é€šè¿‡æ—§camera_idæ‰¾åˆ°device_idï¼Œå†æ‰¾åˆ°devices.id
                    device_uuid = self.old_camera_id_to_device_id.get(old_camera_id)
                    if not device_uuid:
                        self.stats['camera_images']['error'] += 1
                        continue
                    
                    device_db_id = self.device_id_map.get(device_uuid)
                    if not device_db_id:
                        self.stats['camera_images']['error'] += 1
                        continue
                    
                    # è§£ææ—¶é—´
                    ts_utc = datetime.utcnow()
                    if row.get('timestamp'):
                        try:
                            ts_ms = int(row['timestamp'])
                            ts_utc = datetime.fromtimestamp(ts_ms / 1000.0)
                        except:
                            pass
                    
                    image = CameraImage(
                        device_id=device_db_id,  # ä½¿ç”¨device_idè€Œä¸æ˜¯camera_id
                        pond_id=1,
                        image_url=row.get('image_url', ''),
                        ts_utc=ts_utc,
                        timestamp_str=row.get('timestamp_str', ''),
                        width=int(row['width']) if row.get('width') and int(row['width']) > 0 else 1920,
                        height=int(row['height']) if row.get('height') and int(row['height']) > 0 else 1080,
                        format=row.get('format', 'jpg'),
                        size=int(row.get('size', 0)),
                        fps=int(row.get('fps', 0))
                    )
                    
                    if self.batch_id_map:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®åº“ä¸»é”®IDï¼ˆæ•´æ•°ï¼‰
                        image.batch_id = list(self.batch_id_map.values())[0]
                    
                    self.session.add(image)
                    self.stats['camera_images']['success'] += 1
                    
                    if self.stats['camera_images']['success'] % 1000 == 0:
                        self.session.flush()
                        print(f"  è¿›åº¦: {self.stats['camera_images']['success']} æ¡...")
                    
                except Exception as e:
                    self.stats['camera_images']['error'] += 1
                    if self.stats['camera_images']['error'] <= 5:
                        print(f"  âŒ é”™è¯¯: {e}")
        
        self.session.commit()
        print(f"  âœ“ å®Œæˆ: {self.stats['camera_images']['success']} æˆåŠŸ, {self.stats['camera_images']['error']} å¤±è´¥")
    
    def migrate_shrimp_stats(self):
        """æ­¥éª¤9: è¿ç§»è™¾ç»Ÿè®¡æ•°æ®"""
        self.print_section("è¿ç§»è™¾ç»Ÿè®¡æ•°æ® (shrimp_stats.csv)", 9)
        
        csv_path = os.path.join(self.backend_dir, 'db_models/db_datas/shrimp_stats.csv')
        if not os.path.exists(csv_path):
            print("  âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    # è§£ææ—¶é—´
                    ts_utc = datetime.utcnow()
                    if row.get('created_at_source'):
                        try:
                            ts_utc = datetime.strptime(row['created_at_source'], '%Y-%m-%d %H:%M:%S.%f')
                        except:
                            pass
                    
                    stat = ShrimpStats(
                        ts_utc=ts_utc,
                        pond_id=1
                    )
                    
                    if self.batch_id_map:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®åº“ä¸»é”®IDï¼ˆæ•´æ•°ï¼‰
                        stat.batch_id = list(self.batch_id_map.values())[0]
                    
                    if row.get('count'):
                        try:
                            stat.count = int(row['count'])
                        except:
                            pass
                    if row.get('size_mean_cm'):
                        try:
                            stat.size_mean_cm = float(row['size_mean_cm'])
                        except:
                            pass
                    if row.get('weight_mean_g'):
                        try:
                            stat.weight_mean_g = float(row['weight_mean_g'])
                        except:
                            pass
                    
                    self.session.add(stat)
                    self.stats['shrimp_stats']['success'] += 1
                    
                except Exception as e:
                    self.stats['shrimp_stats']['error'] += 1
                    if self.stats['shrimp_stats']['error'] <= 5:
                        print(f"  âŒ é”™è¯¯: {e}")
        
        self.session.commit()
        print(f"  âœ“ å®Œæˆ: {self.stats['shrimp_stats']['success']} æˆåŠŸ, {self.stats['shrimp_stats']['error']} å¤±è´¥")
    
    def print_summary(self):
        """æ‰“å°è¿ç§»æ±‡æ€»"""
        self.print_section("è¿ç§»æ±‡æ€»æŠ¥å‘Š")
        
        print("\nğŸ“Š å„è¡¨è¿ç§»ç»Ÿè®¡:")
        print(f"{'è¡¨å':<20} {'æˆåŠŸ':>8} {'è·³è¿‡':>8} {'å¤±è´¥':>8}")
        print("-" * 50)
        
        for table, stats in sorted(self.stats.items()):
            print(f"{table:<20} {stats['success']:>8} {stats['skip']:>8} {stats['error']:>8}")
        
        total_success = sum(s['success'] for s in self.stats.values())
        total_error = sum(s['error'] for s in self.stats.values())
        
        print("-" * 50)
        print(f"{'æ€»è®¡':<20} {total_success:>8} {0:>8} {total_error:>8}")
        
        print(f"\nâœ… è¿ç§»å®Œæˆ! æˆåŠŸ: {total_success}, å¤±è´¥: {total_error}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ç»¼åˆæ•°æ®è¿ç§»è„šæœ¬ - ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰æ•°æ®è¿ç§»")
    print("=" * 70)
    print("\nâš ï¸  è­¦å‘Š: æ­¤è„šæœ¬å°†æŒ‰ä¾èµ–é¡ºåºè¿ç§»æ‰€æœ‰æ•°æ®")
    print("å»ºè®®åœ¨è¿è¡Œå‰å¤‡ä»½æ•°æ®åº“\n")
    
    try:
        with db_session_factory() as session:
            migrator = DataMigrator(session)
            
            # æŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œè¿ç§»
            migrator.migrate_ponds()              # 1. åŸºç¡€ï¼šæ± å­
            migrator.migrate_batches()            # 2. ä¾èµ–æ± å­ï¼šæ‰¹æ¬¡
            migrator.migrate_device_types()       # 3. åŸºç¡€ï¼šè®¾å¤‡ç±»å‹
            migrator.migrate_sensor_types()       # 4. åŸºç¡€ï¼šä¼ æ„Ÿå™¨ç±»å‹
            migrator.migrate_devices_and_extensions()  # 5. è®¾å¤‡+æ‰©å±•ï¼ˆä¼ æ„Ÿå™¨/å–‚é£Ÿæœº/æ‘„åƒå¤´ï¼‰
            migrator.migrate_sensor_readings()    # 6. ä¾èµ–ä¼ æ„Ÿå™¨ï¼šä¼ æ„Ÿå™¨è¯»æ•°
            migrator.migrate_feeder_logs()        # 7. ä¾èµ–å–‚é£Ÿæœºï¼šå–‚é£Ÿæœºæ—¥å¿—
            migrator.migrate_camera_images()      # 8. ä¾èµ–æ‘„åƒå¤´ï¼šæ‘„åƒå¤´å›¾ç‰‡
            migrator.migrate_shrimp_stats()       # 9. ä¾èµ–å›¾ç‰‡ï¼šè™¾ç»Ÿè®¡
            
            # æ‰“å°æ±‡æ€»
            migrator.print_summary()
            
            return True
            
    except Exception as e:
        print(f"\nâŒ è¿ç§»å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

